{
  "best_metric": 0.955607476635514,
  "best_model_checkpoint": "result-test3/checkpoint-2140",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 2140,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04672897196261682,
      "grad_norm": 1.4199705123901367,
      "learning_rate": 2.3364485981308413e-06,
      "loss": 0.6873,
      "step": 10
    },
    {
      "epoch": 0.09345794392523364,
      "grad_norm": 0.5997723340988159,
      "learning_rate": 4.6728971962616825e-06,
      "loss": 0.669,
      "step": 20
    },
    {
      "epoch": 0.14018691588785046,
      "grad_norm": 1.1181907653808594,
      "learning_rate": 7.009345794392523e-06,
      "loss": 0.6152,
      "step": 30
    },
    {
      "epoch": 0.18691588785046728,
      "grad_norm": 0.9259819984436035,
      "learning_rate": 9.345794392523365e-06,
      "loss": 0.5975,
      "step": 40
    },
    {
      "epoch": 0.2336448598130841,
      "grad_norm": 2.1889140605926514,
      "learning_rate": 1.1682242990654207e-05,
      "loss": 0.5821,
      "step": 50
    },
    {
      "epoch": 0.2803738317757009,
      "grad_norm": 1.88286292552948,
      "learning_rate": 1.4018691588785047e-05,
      "loss": 0.5786,
      "step": 60
    },
    {
      "epoch": 0.32710280373831774,
      "grad_norm": 4.083281993865967,
      "learning_rate": 1.6355140186915887e-05,
      "loss": 0.5213,
      "step": 70
    },
    {
      "epoch": 0.37383177570093457,
      "grad_norm": 7.41007137298584,
      "learning_rate": 1.869158878504673e-05,
      "loss": 0.512,
      "step": 80
    },
    {
      "epoch": 0.4205607476635514,
      "grad_norm": 1.8197340965270996,
      "learning_rate": 2.102803738317757e-05,
      "loss": 0.3916,
      "step": 90
    },
    {
      "epoch": 0.4672897196261682,
      "grad_norm": 0.5407981872558594,
      "learning_rate": 2.3364485981308414e-05,
      "loss": 0.4217,
      "step": 100
    },
    {
      "epoch": 0.514018691588785,
      "grad_norm": 1.3316278457641602,
      "learning_rate": 2.570093457943925e-05,
      "loss": 0.3624,
      "step": 110
    },
    {
      "epoch": 0.5607476635514018,
      "grad_norm": 0.7779858708381653,
      "learning_rate": 2.8037383177570094e-05,
      "loss": 0.2863,
      "step": 120
    },
    {
      "epoch": 0.6074766355140186,
      "grad_norm": 4.2310028076171875,
      "learning_rate": 3.0373831775700934e-05,
      "loss": 0.3326,
      "step": 130
    },
    {
      "epoch": 0.6542056074766355,
      "grad_norm": 3.298424482345581,
      "learning_rate": 3.2710280373831774e-05,
      "loss": 0.5815,
      "step": 140
    },
    {
      "epoch": 0.7009345794392523,
      "grad_norm": 1.9236552715301514,
      "learning_rate": 3.504672897196262e-05,
      "loss": 0.2736,
      "step": 150
    },
    {
      "epoch": 0.7476635514018691,
      "grad_norm": 2.532745599746704,
      "learning_rate": 3.738317757009346e-05,
      "loss": 0.3547,
      "step": 160
    },
    {
      "epoch": 0.794392523364486,
      "grad_norm": 8.095610618591309,
      "learning_rate": 3.97196261682243e-05,
      "loss": 0.4965,
      "step": 170
    },
    {
      "epoch": 0.8411214953271028,
      "grad_norm": 34.977073669433594,
      "learning_rate": 4.205607476635514e-05,
      "loss": 0.5437,
      "step": 180
    },
    {
      "epoch": 0.8878504672897196,
      "grad_norm": 7.9658894538879395,
      "learning_rate": 4.4392523364485984e-05,
      "loss": 0.5072,
      "step": 190
    },
    {
      "epoch": 0.9345794392523364,
      "grad_norm": 37.87523651123047,
      "learning_rate": 4.672897196261683e-05,
      "loss": 0.3778,
      "step": 200
    },
    {
      "epoch": 0.9813084112149533,
      "grad_norm": 1.9404568672180176,
      "learning_rate": 4.9065420560747664e-05,
      "loss": 0.4202,
      "step": 210
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8154205607476636,
      "eval_f1": 0.7431772435532262,
      "eval_loss": 0.4578801095485687,
      "eval_precision": 0.7786486022980621,
      "eval_recall": 0.7244694960212201,
      "eval_runtime": 114.5682,
      "eval_samples_per_second": 3.736,
      "eval_steps_per_second": 0.471,
      "step": 214
    },
    {
      "epoch": 1.02803738317757,
      "grad_norm": 12.647279739379883,
      "learning_rate": 4.9844236760124614e-05,
      "loss": 0.4229,
      "step": 220
    },
    {
      "epoch": 1.074766355140187,
      "grad_norm": 0.8413943648338318,
      "learning_rate": 4.958463136033229e-05,
      "loss": 0.5337,
      "step": 230
    },
    {
      "epoch": 1.1214953271028036,
      "grad_norm": 1.0054218769073486,
      "learning_rate": 4.9325025960539985e-05,
      "loss": 0.579,
      "step": 240
    },
    {
      "epoch": 1.1682242990654206,
      "grad_norm": 1.5928540229797363,
      "learning_rate": 4.9065420560747664e-05,
      "loss": 0.533,
      "step": 250
    },
    {
      "epoch": 1.2149532710280373,
      "grad_norm": 3.836068630218506,
      "learning_rate": 4.880581516095535e-05,
      "loss": 0.6035,
      "step": 260
    },
    {
      "epoch": 1.2616822429906542,
      "grad_norm": 18.137908935546875,
      "learning_rate": 4.8546209761163035e-05,
      "loss": 0.4721,
      "step": 270
    },
    {
      "epoch": 1.308411214953271,
      "grad_norm": 5.9242844581604,
      "learning_rate": 4.828660436137072e-05,
      "loss": 0.3576,
      "step": 280
    },
    {
      "epoch": 1.355140186915888,
      "grad_norm": 1.0808707475662231,
      "learning_rate": 4.80269989615784e-05,
      "loss": 0.2821,
      "step": 290
    },
    {
      "epoch": 1.4018691588785046,
      "grad_norm": 6.645605087280273,
      "learning_rate": 4.776739356178609e-05,
      "loss": 0.6766,
      "step": 300
    },
    {
      "epoch": 1.4485981308411215,
      "grad_norm": 4.742471218109131,
      "learning_rate": 4.750778816199377e-05,
      "loss": 0.4013,
      "step": 310
    },
    {
      "epoch": 1.4953271028037383,
      "grad_norm": 1.0556535720825195,
      "learning_rate": 4.7248182762201456e-05,
      "loss": 0.2859,
      "step": 320
    },
    {
      "epoch": 1.542056074766355,
      "grad_norm": 1.1809293031692505,
      "learning_rate": 4.698857736240914e-05,
      "loss": 0.2977,
      "step": 330
    },
    {
      "epoch": 1.588785046728972,
      "grad_norm": 0.8700057864189148,
      "learning_rate": 4.672897196261683e-05,
      "loss": 0.2452,
      "step": 340
    },
    {
      "epoch": 1.6355140186915889,
      "grad_norm": 28.448869705200195,
      "learning_rate": 4.6469366562824506e-05,
      "loss": 0.2944,
      "step": 350
    },
    {
      "epoch": 1.6822429906542056,
      "grad_norm": 0.5248096585273743,
      "learning_rate": 4.620976116303219e-05,
      "loss": 0.2285,
      "step": 360
    },
    {
      "epoch": 1.7289719626168223,
      "grad_norm": 1.2097680568695068,
      "learning_rate": 4.595015576323988e-05,
      "loss": 0.3092,
      "step": 370
    },
    {
      "epoch": 1.7757009345794392,
      "grad_norm": 1.4833085536956787,
      "learning_rate": 4.569055036344756e-05,
      "loss": 0.332,
      "step": 380
    },
    {
      "epoch": 1.8224299065420562,
      "grad_norm": 0.3810364305973053,
      "learning_rate": 4.543094496365525e-05,
      "loss": 0.3017,
      "step": 390
    },
    {
      "epoch": 1.8691588785046729,
      "grad_norm": 0.3866789937019348,
      "learning_rate": 4.517133956386293e-05,
      "loss": 0.2367,
      "step": 400
    },
    {
      "epoch": 1.9158878504672896,
      "grad_norm": 0.3405280113220215,
      "learning_rate": 4.491173416407061e-05,
      "loss": 0.1421,
      "step": 410
    },
    {
      "epoch": 1.9626168224299065,
      "grad_norm": 0.3365054726600647,
      "learning_rate": 4.46521287642783e-05,
      "loss": 0.149,
      "step": 420
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.927570093457944,
      "eval_f1": 0.9037260095054964,
      "eval_loss": 0.27198490500450134,
      "eval_precision": 0.928172300512726,
      "eval_recall": 0.8853337754199824,
      "eval_runtime": 112.4641,
      "eval_samples_per_second": 3.806,
      "eval_steps_per_second": 0.48,
      "step": 428
    },
    {
      "epoch": 2.0093457943925235,
      "grad_norm": 0.26689669489860535,
      "learning_rate": 4.4392523364485984e-05,
      "loss": 0.092,
      "step": 430
    },
    {
      "epoch": 2.05607476635514,
      "grad_norm": 69.2972183227539,
      "learning_rate": 4.413291796469366e-05,
      "loss": 0.2313,
      "step": 440
    },
    {
      "epoch": 2.102803738317757,
      "grad_norm": 0.2148379534482956,
      "learning_rate": 4.3873312564901355e-05,
      "loss": 0.0786,
      "step": 450
    },
    {
      "epoch": 2.149532710280374,
      "grad_norm": 28.986331939697266,
      "learning_rate": 4.3613707165109034e-05,
      "loss": 0.4715,
      "step": 460
    },
    {
      "epoch": 2.196261682242991,
      "grad_norm": 25.070833206176758,
      "learning_rate": 4.335410176531672e-05,
      "loss": 0.2895,
      "step": 470
    },
    {
      "epoch": 2.2429906542056073,
      "grad_norm": 2.8870835304260254,
      "learning_rate": 4.3094496365524405e-05,
      "loss": 0.1706,
      "step": 480
    },
    {
      "epoch": 2.289719626168224,
      "grad_norm": 0.31831157207489014,
      "learning_rate": 4.283489096573209e-05,
      "loss": 0.1518,
      "step": 490
    },
    {
      "epoch": 2.336448598130841,
      "grad_norm": 1.6031066179275513,
      "learning_rate": 4.257528556593977e-05,
      "loss": 0.2692,
      "step": 500
    },
    {
      "epoch": 2.383177570093458,
      "grad_norm": 4.459775447845459,
      "learning_rate": 4.231568016614746e-05,
      "loss": 0.5049,
      "step": 510
    },
    {
      "epoch": 2.4299065420560746,
      "grad_norm": 20.69326400756836,
      "learning_rate": 4.205607476635514e-05,
      "loss": 0.3936,
      "step": 520
    },
    {
      "epoch": 2.4766355140186915,
      "grad_norm": 0.6999776363372803,
      "learning_rate": 4.1796469366562826e-05,
      "loss": 0.4887,
      "step": 530
    },
    {
      "epoch": 2.5233644859813085,
      "grad_norm": 0.4084005355834961,
      "learning_rate": 4.153686396677051e-05,
      "loss": 0.0727,
      "step": 540
    },
    {
      "epoch": 2.5700934579439254,
      "grad_norm": 1.6055376529693604,
      "learning_rate": 4.12772585669782e-05,
      "loss": 0.1201,
      "step": 550
    },
    {
      "epoch": 2.616822429906542,
      "grad_norm": 101.16441345214844,
      "learning_rate": 4.101765316718588e-05,
      "loss": 0.179,
      "step": 560
    },
    {
      "epoch": 2.663551401869159,
      "grad_norm": 0.3159500062465668,
      "learning_rate": 4.075804776739356e-05,
      "loss": 0.1308,
      "step": 570
    },
    {
      "epoch": 2.710280373831776,
      "grad_norm": 8.927542686462402,
      "learning_rate": 4.049844236760125e-05,
      "loss": 0.2171,
      "step": 580
    },
    {
      "epoch": 2.7570093457943923,
      "grad_norm": 17.62223243713379,
      "learning_rate": 4.023883696780893e-05,
      "loss": 0.3155,
      "step": 590
    },
    {
      "epoch": 2.803738317757009,
      "grad_norm": 1.274251937866211,
      "learning_rate": 3.997923156801662e-05,
      "loss": 0.2389,
      "step": 600
    },
    {
      "epoch": 2.850467289719626,
      "grad_norm": 8.079526901245117,
      "learning_rate": 3.97196261682243e-05,
      "loss": 0.1157,
      "step": 610
    },
    {
      "epoch": 2.897196261682243,
      "grad_norm": 0.8063177466392517,
      "learning_rate": 3.946002076843199e-05,
      "loss": 0.0763,
      "step": 620
    },
    {
      "epoch": 2.94392523364486,
      "grad_norm": 6.727901935577393,
      "learning_rate": 3.920041536863967e-05,
      "loss": 0.3332,
      "step": 630
    },
    {
      "epoch": 2.9906542056074765,
      "grad_norm": 32.38642501831055,
      "learning_rate": 3.8940809968847354e-05,
      "loss": 0.1728,
      "step": 640
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9228971962616822,
      "eval_f1": 0.9065520732021992,
      "eval_loss": 0.24809521436691284,
      "eval_precision": 0.8924557155600866,
      "eval_recall": 0.9254531388152077,
      "eval_runtime": 113.0571,
      "eval_samples_per_second": 3.786,
      "eval_steps_per_second": 0.478,
      "step": 642
    },
    {
      "epoch": 3.0373831775700935,
      "grad_norm": 0.2371823638677597,
      "learning_rate": 3.868120456905504e-05,
      "loss": 0.1354,
      "step": 650
    },
    {
      "epoch": 3.0841121495327104,
      "grad_norm": 0.22392557561397552,
      "learning_rate": 3.8421599169262725e-05,
      "loss": 0.1183,
      "step": 660
    },
    {
      "epoch": 3.130841121495327,
      "grad_norm": 3.570621967315674,
      "learning_rate": 3.8161993769470404e-05,
      "loss": 0.3154,
      "step": 670
    },
    {
      "epoch": 3.177570093457944,
      "grad_norm": 0.17789886891841888,
      "learning_rate": 3.7902388369678096e-05,
      "loss": 0.0915,
      "step": 680
    },
    {
      "epoch": 3.2242990654205608,
      "grad_norm": 0.274810791015625,
      "learning_rate": 3.7642782969885775e-05,
      "loss": 0.2048,
      "step": 690
    },
    {
      "epoch": 3.2710280373831777,
      "grad_norm": 0.19962570071220398,
      "learning_rate": 3.738317757009346e-05,
      "loss": 0.1433,
      "step": 700
    },
    {
      "epoch": 3.317757009345794,
      "grad_norm": 0.16853034496307373,
      "learning_rate": 3.7123572170301146e-05,
      "loss": 0.1119,
      "step": 710
    },
    {
      "epoch": 3.364485981308411,
      "grad_norm": 0.18896551430225372,
      "learning_rate": 3.686396677050883e-05,
      "loss": 0.1772,
      "step": 720
    },
    {
      "epoch": 3.411214953271028,
      "grad_norm": 0.21711254119873047,
      "learning_rate": 3.660436137071651e-05,
      "loss": 0.0633,
      "step": 730
    },
    {
      "epoch": 3.457943925233645,
      "grad_norm": 0.15861299633979797,
      "learning_rate": 3.6344755970924196e-05,
      "loss": 0.0666,
      "step": 740
    },
    {
      "epoch": 3.5046728971962615,
      "grad_norm": 0.09504580497741699,
      "learning_rate": 3.608515057113188e-05,
      "loss": 0.059,
      "step": 750
    },
    {
      "epoch": 3.5514018691588785,
      "grad_norm": 0.101382777094841,
      "learning_rate": 3.582554517133957e-05,
      "loss": 0.0883,
      "step": 760
    },
    {
      "epoch": 3.5981308411214954,
      "grad_norm": 17.650888442993164,
      "learning_rate": 3.556593977154725e-05,
      "loss": 0.1164,
      "step": 770
    },
    {
      "epoch": 3.6448598130841123,
      "grad_norm": 0.1925002783536911,
      "learning_rate": 3.530633437175493e-05,
      "loss": 0.2339,
      "step": 780
    },
    {
      "epoch": 3.691588785046729,
      "grad_norm": 0.11914950609207153,
      "learning_rate": 3.504672897196262e-05,
      "loss": 0.1116,
      "step": 790
    },
    {
      "epoch": 3.7383177570093458,
      "grad_norm": 0.10024057328701019,
      "learning_rate": 3.47871235721703e-05,
      "loss": 0.186,
      "step": 800
    },
    {
      "epoch": 3.7850467289719627,
      "grad_norm": 0.10420244932174683,
      "learning_rate": 3.452751817237799e-05,
      "loss": 0.2373,
      "step": 810
    },
    {
      "epoch": 3.831775700934579,
      "grad_norm": 0.26511335372924805,
      "learning_rate": 3.426791277258567e-05,
      "loss": 0.0076,
      "step": 820
    },
    {
      "epoch": 3.878504672897196,
      "grad_norm": 3.195185899734497,
      "learning_rate": 3.400830737279336e-05,
      "loss": 0.2158,
      "step": 830
    },
    {
      "epoch": 3.925233644859813,
      "grad_norm": 0.09049754589796066,
      "learning_rate": 3.374870197300104e-05,
      "loss": 0.0059,
      "step": 840
    },
    {
      "epoch": 3.97196261682243,
      "grad_norm": 0.09821316599845886,
      "learning_rate": 3.3489096573208724e-05,
      "loss": 0.2435,
      "step": 850
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9532710280373832,
      "eval_f1": 0.9411877868469508,
      "eval_loss": 0.18803970515727997,
      "eval_precision": 0.9388737014762165,
      "eval_recall": 0.943578691423519,
      "eval_runtime": 112.7459,
      "eval_samples_per_second": 3.796,
      "eval_steps_per_second": 0.479,
      "step": 856
    },
    {
      "epoch": 4.018691588785047,
      "grad_norm": 0.6548379063606262,
      "learning_rate": 3.322949117341641e-05,
      "loss": 0.28,
      "step": 860
    },
    {
      "epoch": 4.065420560747664,
      "grad_norm": 0.10652638226747513,
      "learning_rate": 3.2969885773624095e-05,
      "loss": 0.0085,
      "step": 870
    },
    {
      "epoch": 4.11214953271028,
      "grad_norm": 0.15395711362361908,
      "learning_rate": 3.2710280373831774e-05,
      "loss": 0.1098,
      "step": 880
    },
    {
      "epoch": 4.158878504672897,
      "grad_norm": 3.6095778942108154,
      "learning_rate": 3.2450674974039466e-05,
      "loss": 0.1991,
      "step": 890
    },
    {
      "epoch": 4.205607476635514,
      "grad_norm": 0.20119911432266235,
      "learning_rate": 3.2191069574247145e-05,
      "loss": 0.064,
      "step": 900
    },
    {
      "epoch": 4.252336448598131,
      "grad_norm": 0.08721528202295303,
      "learning_rate": 3.193146417445483e-05,
      "loss": 0.0711,
      "step": 910
    },
    {
      "epoch": 4.299065420560748,
      "grad_norm": 0.11915075778961182,
      "learning_rate": 3.1671858774662516e-05,
      "loss": 0.0076,
      "step": 920
    },
    {
      "epoch": 4.345794392523365,
      "grad_norm": 0.08661315590143204,
      "learning_rate": 3.14122533748702e-05,
      "loss": 0.0051,
      "step": 930
    },
    {
      "epoch": 4.392523364485982,
      "grad_norm": 0.06874643266201019,
      "learning_rate": 3.115264797507788e-05,
      "loss": 0.0058,
      "step": 940
    },
    {
      "epoch": 4.4392523364485985,
      "grad_norm": 0.08346359431743622,
      "learning_rate": 3.0893042575285566e-05,
      "loss": 0.0041,
      "step": 950
    },
    {
      "epoch": 4.485981308411215,
      "grad_norm": 11.799239158630371,
      "learning_rate": 3.063343717549325e-05,
      "loss": 0.1314,
      "step": 960
    },
    {
      "epoch": 4.5327102803738315,
      "grad_norm": 0.3641832172870636,
      "learning_rate": 3.0373831775700934e-05,
      "loss": 0.0647,
      "step": 970
    },
    {
      "epoch": 4.579439252336448,
      "grad_norm": 0.09541206806898117,
      "learning_rate": 3.0114226375908622e-05,
      "loss": 0.1784,
      "step": 980
    },
    {
      "epoch": 4.626168224299065,
      "grad_norm": 0.18802092969417572,
      "learning_rate": 2.9854620976116305e-05,
      "loss": 0.0093,
      "step": 990
    },
    {
      "epoch": 4.672897196261682,
      "grad_norm": 0.06731364876031876,
      "learning_rate": 2.9595015576323987e-05,
      "loss": 0.2113,
      "step": 1000
    },
    {
      "epoch": 4.719626168224299,
      "grad_norm": 0.36342740058898926,
      "learning_rate": 2.9335410176531676e-05,
      "loss": 0.1503,
      "step": 1010
    },
    {
      "epoch": 4.766355140186916,
      "grad_norm": 0.137290820479393,
      "learning_rate": 2.9075804776739358e-05,
      "loss": 0.0635,
      "step": 1020
    },
    {
      "epoch": 4.813084112149532,
      "grad_norm": 0.09784936904907227,
      "learning_rate": 2.881619937694704e-05,
      "loss": 0.1142,
      "step": 1030
    },
    {
      "epoch": 4.859813084112149,
      "grad_norm": 0.08485659956932068,
      "learning_rate": 2.855659397715473e-05,
      "loss": 0.1023,
      "step": 1040
    },
    {
      "epoch": 4.906542056074766,
      "grad_norm": 0.06325910240411758,
      "learning_rate": 2.829698857736241e-05,
      "loss": 0.0589,
      "step": 1050
    },
    {
      "epoch": 4.953271028037383,
      "grad_norm": 0.05171041563153267,
      "learning_rate": 2.8037383177570094e-05,
      "loss": 0.1813,
      "step": 1060
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.47468069195747375,
      "learning_rate": 2.777777777777778e-05,
      "loss": 0.1813,
      "step": 1070
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9392523364485982,
      "eval_f1": 0.9209367095802428,
      "eval_loss": 0.2760252058506012,
      "eval_precision": 0.93431384038439,
      "eval_recall": 0.9095932802829354,
      "eval_runtime": 112.9129,
      "eval_samples_per_second": 3.791,
      "eval_steps_per_second": 0.478,
      "step": 1070
    },
    {
      "epoch": 5.046728971962617,
      "grad_norm": 0.13654492795467377,
      "learning_rate": 2.751817237798546e-05,
      "loss": 0.0056,
      "step": 1080
    },
    {
      "epoch": 5.093457943925234,
      "grad_norm": 0.06769296526908875,
      "learning_rate": 2.7258566978193147e-05,
      "loss": 0.1076,
      "step": 1090
    },
    {
      "epoch": 5.140186915887851,
      "grad_norm": 0.14730402827262878,
      "learning_rate": 2.6998961578400832e-05,
      "loss": 0.0475,
      "step": 1100
    },
    {
      "epoch": 5.186915887850467,
      "grad_norm": 0.04844004660844803,
      "learning_rate": 2.6739356178608515e-05,
      "loss": 0.0046,
      "step": 1110
    },
    {
      "epoch": 5.233644859813084,
      "grad_norm": 0.04910285025835037,
      "learning_rate": 2.6479750778816197e-05,
      "loss": 0.0047,
      "step": 1120
    },
    {
      "epoch": 5.280373831775701,
      "grad_norm": 0.08658809214830399,
      "learning_rate": 2.6220145379023886e-05,
      "loss": 0.0819,
      "step": 1130
    },
    {
      "epoch": 5.327102803738318,
      "grad_norm": 0.05108688771724701,
      "learning_rate": 2.5960539979231568e-05,
      "loss": 0.1827,
      "step": 1140
    },
    {
      "epoch": 5.373831775700935,
      "grad_norm": 0.06035030260682106,
      "learning_rate": 2.570093457943925e-05,
      "loss": 0.0588,
      "step": 1150
    },
    {
      "epoch": 5.420560747663552,
      "grad_norm": 0.06488864123821259,
      "learning_rate": 2.544132917964694e-05,
      "loss": 0.1447,
      "step": 1160
    },
    {
      "epoch": 5.4672897196261685,
      "grad_norm": 0.041124120354652405,
      "learning_rate": 2.518172377985462e-05,
      "loss": 0.0039,
      "step": 1170
    },
    {
      "epoch": 5.5140186915887845,
      "grad_norm": 1.9863044023513794,
      "learning_rate": 2.4922118380062307e-05,
      "loss": 0.0037,
      "step": 1180
    },
    {
      "epoch": 5.5607476635514015,
      "grad_norm": 0.054513685405254364,
      "learning_rate": 2.4662512980269992e-05,
      "loss": 0.0031,
      "step": 1190
    },
    {
      "epoch": 5.607476635514018,
      "grad_norm": 0.0704091489315033,
      "learning_rate": 2.4402907580477675e-05,
      "loss": 0.0031,
      "step": 1200
    },
    {
      "epoch": 5.654205607476635,
      "grad_norm": 0.05597405135631561,
      "learning_rate": 2.414330218068536e-05,
      "loss": 0.0512,
      "step": 1210
    },
    {
      "epoch": 5.700934579439252,
      "grad_norm": 0.02941606380045414,
      "learning_rate": 2.3883696780893046e-05,
      "loss": 0.1556,
      "step": 1220
    },
    {
      "epoch": 5.747663551401869,
      "grad_norm": 0.04782594367861748,
      "learning_rate": 2.3624091381100728e-05,
      "loss": 0.2396,
      "step": 1230
    },
    {
      "epoch": 5.794392523364486,
      "grad_norm": 0.08142407238483429,
      "learning_rate": 2.3364485981308414e-05,
      "loss": 0.0054,
      "step": 1240
    },
    {
      "epoch": 5.841121495327103,
      "grad_norm": 0.03347614407539368,
      "learning_rate": 2.3104880581516096e-05,
      "loss": 0.0604,
      "step": 1250
    },
    {
      "epoch": 5.88785046728972,
      "grad_norm": 0.06305515021085739,
      "learning_rate": 2.284527518172378e-05,
      "loss": 0.0679,
      "step": 1260
    },
    {
      "epoch": 5.934579439252336,
      "grad_norm": 0.0683167576789856,
      "learning_rate": 2.2585669781931463e-05,
      "loss": 0.0028,
      "step": 1270
    },
    {
      "epoch": 5.981308411214953,
      "grad_norm": 14.462015151977539,
      "learning_rate": 2.232606438213915e-05,
      "loss": 0.1155,
      "step": 1280
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9392523364485982,
      "eval_f1": 0.9227114877066259,
      "eval_loss": 0.29428377747535706,
      "eval_precision": 0.9250754274220583,
      "eval_recall": 0.9204244031830239,
      "eval_runtime": 113.0652,
      "eval_samples_per_second": 3.785,
      "eval_steps_per_second": 0.478,
      "step": 1284
    },
    {
      "epoch": 6.02803738317757,
      "grad_norm": 140.1354217529297,
      "learning_rate": 2.206645898234683e-05,
      "loss": 0.1967,
      "step": 1290
    },
    {
      "epoch": 6.074766355140187,
      "grad_norm": 26.110496520996094,
      "learning_rate": 2.1806853582554517e-05,
      "loss": 0.0983,
      "step": 1300
    },
    {
      "epoch": 6.121495327102804,
      "grad_norm": 0.04613480344414711,
      "learning_rate": 2.1547248182762202e-05,
      "loss": 0.0133,
      "step": 1310
    },
    {
      "epoch": 6.168224299065421,
      "grad_norm": 17.826906204223633,
      "learning_rate": 2.1287642782969885e-05,
      "loss": 0.07,
      "step": 1320
    },
    {
      "epoch": 6.214953271028038,
      "grad_norm": 0.06889603286981583,
      "learning_rate": 2.102803738317757e-05,
      "loss": 0.0035,
      "step": 1330
    },
    {
      "epoch": 6.261682242990654,
      "grad_norm": 0.2971983850002289,
      "learning_rate": 2.0768431983385256e-05,
      "loss": 0.004,
      "step": 1340
    },
    {
      "epoch": 6.308411214953271,
      "grad_norm": 0.025139696896076202,
      "learning_rate": 2.050882658359294e-05,
      "loss": 0.0023,
      "step": 1350
    },
    {
      "epoch": 6.355140186915888,
      "grad_norm": 0.037016015499830246,
      "learning_rate": 2.0249221183800623e-05,
      "loss": 0.0021,
      "step": 1360
    },
    {
      "epoch": 6.401869158878505,
      "grad_norm": 0.030941668897867203,
      "learning_rate": 1.998961578400831e-05,
      "loss": 0.0021,
      "step": 1370
    },
    {
      "epoch": 6.4485981308411215,
      "grad_norm": 0.03326176106929779,
      "learning_rate": 1.9730010384215995e-05,
      "loss": 0.002,
      "step": 1380
    },
    {
      "epoch": 6.4953271028037385,
      "grad_norm": 0.025700658559799194,
      "learning_rate": 1.9470404984423677e-05,
      "loss": 0.0639,
      "step": 1390
    },
    {
      "epoch": 6.542056074766355,
      "grad_norm": 0.028559759259223938,
      "learning_rate": 1.9210799584631362e-05,
      "loss": 0.0566,
      "step": 1400
    },
    {
      "epoch": 6.588785046728972,
      "grad_norm": 0.024792075157165527,
      "learning_rate": 1.8951194184839048e-05,
      "loss": 0.114,
      "step": 1410
    },
    {
      "epoch": 6.635514018691588,
      "grad_norm": 0.36148130893707275,
      "learning_rate": 1.869158878504673e-05,
      "loss": 0.0885,
      "step": 1420
    },
    {
      "epoch": 6.682242990654205,
      "grad_norm": 0.03491412475705147,
      "learning_rate": 1.8431983385254416e-05,
      "loss": 0.0022,
      "step": 1430
    },
    {
      "epoch": 6.728971962616822,
      "grad_norm": 0.027479147538542747,
      "learning_rate": 1.8172377985462098e-05,
      "loss": 0.0018,
      "step": 1440
    },
    {
      "epoch": 6.775700934579439,
      "grad_norm": 0.037434592843055725,
      "learning_rate": 1.7912772585669783e-05,
      "loss": 0.002,
      "step": 1450
    },
    {
      "epoch": 6.822429906542056,
      "grad_norm": 0.03125884756445885,
      "learning_rate": 1.7653167185877466e-05,
      "loss": 0.0016,
      "step": 1460
    },
    {
      "epoch": 6.869158878504673,
      "grad_norm": 0.04554932191967964,
      "learning_rate": 1.739356178608515e-05,
      "loss": 0.0017,
      "step": 1470
    },
    {
      "epoch": 6.91588785046729,
      "grad_norm": 0.023197339847683907,
      "learning_rate": 1.7133956386292833e-05,
      "loss": 0.0016,
      "step": 1480
    },
    {
      "epoch": 6.962616822429906,
      "grad_norm": 0.025503380224108696,
      "learning_rate": 1.687435098650052e-05,
      "loss": 0.0713,
      "step": 1490
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9509345794392523,
      "eval_f1": 0.9370513296400832,
      "eval_loss": 0.2928023040294647,
      "eval_precision": 0.9434592321027653,
      "eval_recall": 0.9311450044208665,
      "eval_runtime": 114.0207,
      "eval_samples_per_second": 3.754,
      "eval_steps_per_second": 0.474,
      "step": 1498
    },
    {
      "epoch": 7.009345794392523,
      "grad_norm": 0.04294333606958389,
      "learning_rate": 1.6614745586708205e-05,
      "loss": 0.0757,
      "step": 1500
    },
    {
      "epoch": 7.05607476635514,
      "grad_norm": 0.0353841558098793,
      "learning_rate": 1.6355140186915887e-05,
      "loss": 0.0016,
      "step": 1510
    },
    {
      "epoch": 7.102803738317757,
      "grad_norm": 0.02364836260676384,
      "learning_rate": 1.6095534787123572e-05,
      "loss": 0.0015,
      "step": 1520
    },
    {
      "epoch": 7.149532710280374,
      "grad_norm": 0.048935793340206146,
      "learning_rate": 1.5835929387331258e-05,
      "loss": 0.0014,
      "step": 1530
    },
    {
      "epoch": 7.196261682242991,
      "grad_norm": 0.017563557252287865,
      "learning_rate": 1.557632398753894e-05,
      "loss": 0.0011,
      "step": 1540
    },
    {
      "epoch": 7.242990654205608,
      "grad_norm": 0.020497946068644524,
      "learning_rate": 1.5316718587746626e-05,
      "loss": 0.0012,
      "step": 1550
    },
    {
      "epoch": 7.289719626168225,
      "grad_norm": 0.05340449884533882,
      "learning_rate": 1.5057113187954311e-05,
      "loss": 0.0013,
      "step": 1560
    },
    {
      "epoch": 7.336448598130841,
      "grad_norm": 0.03343347832560539,
      "learning_rate": 1.4797507788161993e-05,
      "loss": 0.0013,
      "step": 1570
    },
    {
      "epoch": 7.383177570093458,
      "grad_norm": 0.023706352338194847,
      "learning_rate": 1.4537902388369679e-05,
      "loss": 0.0765,
      "step": 1580
    },
    {
      "epoch": 7.429906542056075,
      "grad_norm": 0.018237262964248657,
      "learning_rate": 1.4278296988577365e-05,
      "loss": 0.0012,
      "step": 1590
    },
    {
      "epoch": 7.4766355140186915,
      "grad_norm": 0.029904374852776527,
      "learning_rate": 1.4018691588785047e-05,
      "loss": 0.0014,
      "step": 1600
    },
    {
      "epoch": 7.5233644859813085,
      "grad_norm": 0.0307939350605011,
      "learning_rate": 1.375908618899273e-05,
      "loss": 0.0909,
      "step": 1610
    },
    {
      "epoch": 7.570093457943925,
      "grad_norm": 0.025498902425169945,
      "learning_rate": 1.3499480789200416e-05,
      "loss": 0.0013,
      "step": 1620
    },
    {
      "epoch": 7.616822429906542,
      "grad_norm": 0.0338970422744751,
      "learning_rate": 1.3239875389408098e-05,
      "loss": 0.0014,
      "step": 1630
    },
    {
      "epoch": 7.663551401869158,
      "grad_norm": 0.028209080919623375,
      "learning_rate": 1.2980269989615784e-05,
      "loss": 0.0692,
      "step": 1640
    },
    {
      "epoch": 7.710280373831775,
      "grad_norm": 0.027736356481909752,
      "learning_rate": 1.272066458982347e-05,
      "loss": 0.0015,
      "step": 1650
    },
    {
      "epoch": 7.757009345794392,
      "grad_norm": 0.07931604981422424,
      "learning_rate": 1.2461059190031153e-05,
      "loss": 0.0016,
      "step": 1660
    },
    {
      "epoch": 7.803738317757009,
      "grad_norm": 0.01945306360721588,
      "learning_rate": 1.2201453790238837e-05,
      "loss": 0.0045,
      "step": 1670
    },
    {
      "epoch": 7.850467289719626,
      "grad_norm": 0.026109615340828896,
      "learning_rate": 1.1941848390446523e-05,
      "loss": 0.0013,
      "step": 1680
    },
    {
      "epoch": 7.897196261682243,
      "grad_norm": 0.037418123334646225,
      "learning_rate": 1.1682242990654207e-05,
      "loss": 0.0013,
      "step": 1690
    },
    {
      "epoch": 7.94392523364486,
      "grad_norm": 0.022045614197850227,
      "learning_rate": 1.142263759086189e-05,
      "loss": 0.0054,
      "step": 1700
    },
    {
      "epoch": 7.990654205607477,
      "grad_norm": 0.027011195197701454,
      "learning_rate": 1.1163032191069575e-05,
      "loss": 0.0013,
      "step": 1710
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9462616822429907,
      "eval_f1": 0.9302630367174605,
      "eval_loss": 0.33517971634864807,
      "eval_precision": 0.942367601246106,
      "eval_recall": 0.9198165340406719,
      "eval_runtime": 112.0118,
      "eval_samples_per_second": 3.821,
      "eval_steps_per_second": 0.482,
      "step": 1712
    },
    {
      "epoch": 8.037383177570094,
      "grad_norm": 0.02295798808336258,
      "learning_rate": 1.0903426791277258e-05,
      "loss": 0.0014,
      "step": 1720
    },
    {
      "epoch": 8.08411214953271,
      "grad_norm": 0.06979899853467941,
      "learning_rate": 1.0643821391484942e-05,
      "loss": 0.0012,
      "step": 1730
    },
    {
      "epoch": 8.130841121495328,
      "grad_norm": 0.014401108026504517,
      "learning_rate": 1.0384215991692628e-05,
      "loss": 0.001,
      "step": 1740
    },
    {
      "epoch": 8.177570093457945,
      "grad_norm": 0.019501036033034325,
      "learning_rate": 1.0124610591900312e-05,
      "loss": 0.001,
      "step": 1750
    },
    {
      "epoch": 8.22429906542056,
      "grad_norm": 0.021891802549362183,
      "learning_rate": 9.865005192107997e-06,
      "loss": 0.001,
      "step": 1760
    },
    {
      "epoch": 8.271028037383177,
      "grad_norm": 0.02319043129682541,
      "learning_rate": 9.605399792315681e-06,
      "loss": 0.001,
      "step": 1770
    },
    {
      "epoch": 8.317757009345794,
      "grad_norm": 0.018497342243790627,
      "learning_rate": 9.345794392523365e-06,
      "loss": 0.0009,
      "step": 1780
    },
    {
      "epoch": 8.36448598130841,
      "grad_norm": 0.018312454223632812,
      "learning_rate": 9.086188992731049e-06,
      "loss": 0.001,
      "step": 1790
    },
    {
      "epoch": 8.411214953271028,
      "grad_norm": 2.608928918838501,
      "learning_rate": 8.826583592938733e-06,
      "loss": 0.0784,
      "step": 1800
    },
    {
      "epoch": 8.457943925233645,
      "grad_norm": 0.017869412899017334,
      "learning_rate": 8.566978193146417e-06,
      "loss": 0.0008,
      "step": 1810
    },
    {
      "epoch": 8.504672897196262,
      "grad_norm": 0.013500277884304523,
      "learning_rate": 8.307372793354102e-06,
      "loss": 0.0218,
      "step": 1820
    },
    {
      "epoch": 8.551401869158878,
      "grad_norm": 0.022035440430045128,
      "learning_rate": 8.047767393561786e-06,
      "loss": 0.001,
      "step": 1830
    },
    {
      "epoch": 8.598130841121495,
      "grad_norm": 0.016021212562918663,
      "learning_rate": 7.78816199376947e-06,
      "loss": 0.001,
      "step": 1840
    },
    {
      "epoch": 8.644859813084112,
      "grad_norm": 0.040300894528627396,
      "learning_rate": 7.528556593977156e-06,
      "loss": 0.001,
      "step": 1850
    },
    {
      "epoch": 8.69158878504673,
      "grad_norm": 0.022020217031240463,
      "learning_rate": 7.2689511941848395e-06,
      "loss": 0.001,
      "step": 1860
    },
    {
      "epoch": 8.738317757009346,
      "grad_norm": 0.01894226484000683,
      "learning_rate": 7.009345794392523e-06,
      "loss": 0.0942,
      "step": 1870
    },
    {
      "epoch": 8.785046728971963,
      "grad_norm": 0.015544729307293892,
      "learning_rate": 6.749740394600208e-06,
      "loss": 0.0011,
      "step": 1880
    },
    {
      "epoch": 8.83177570093458,
      "grad_norm": 0.04672155901789665,
      "learning_rate": 6.490134994807892e-06,
      "loss": 0.001,
      "step": 1890
    },
    {
      "epoch": 8.878504672897197,
      "grad_norm": 0.017742998898029327,
      "learning_rate": 6.230529595015577e-06,
      "loss": 0.0501,
      "step": 1900
    },
    {
      "epoch": 8.925233644859812,
      "grad_norm": 0.020888568833470345,
      "learning_rate": 5.9709241952232614e-06,
      "loss": 0.0595,
      "step": 1910
    },
    {
      "epoch": 8.97196261682243,
      "grad_norm": 0.02292877435684204,
      "learning_rate": 5.711318795430945e-06,
      "loss": 0.0009,
      "step": 1920
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9532710280373832,
      "eval_f1": 0.9402167839982121,
      "eval_loss": 0.28010445833206177,
      "eval_precision": 0.9452983725135624,
      "eval_recall": 0.9354553492484527,
      "eval_runtime": 112.8365,
      "eval_samples_per_second": 3.793,
      "eval_steps_per_second": 0.479,
      "step": 1926
    },
    {
      "epoch": 9.018691588785046,
      "grad_norm": 0.015589587390422821,
      "learning_rate": 5.451713395638629e-06,
      "loss": 0.0009,
      "step": 1930
    },
    {
      "epoch": 9.065420560747663,
      "grad_norm": 0.017308425158262253,
      "learning_rate": 5.192107995846314e-06,
      "loss": 0.0008,
      "step": 1940
    },
    {
      "epoch": 9.11214953271028,
      "grad_norm": 0.01485748216509819,
      "learning_rate": 4.932502596053999e-06,
      "loss": 0.0008,
      "step": 1950
    },
    {
      "epoch": 9.158878504672897,
      "grad_norm": 0.022021910175681114,
      "learning_rate": 4.6728971962616825e-06,
      "loss": 0.001,
      "step": 1960
    },
    {
      "epoch": 9.205607476635514,
      "grad_norm": 0.014926538802683353,
      "learning_rate": 4.413291796469366e-06,
      "loss": 0.0009,
      "step": 1970
    },
    {
      "epoch": 9.25233644859813,
      "grad_norm": 0.021673044189810753,
      "learning_rate": 4.153686396677051e-06,
      "loss": 0.0009,
      "step": 1980
    },
    {
      "epoch": 9.299065420560748,
      "grad_norm": 0.014625097624957561,
      "learning_rate": 3.894080996884735e-06,
      "loss": 0.0009,
      "step": 1990
    },
    {
      "epoch": 9.345794392523365,
      "grad_norm": 0.02105574496090412,
      "learning_rate": 3.6344755970924198e-06,
      "loss": 0.0009,
      "step": 2000
    },
    {
      "epoch": 9.392523364485982,
      "grad_norm": 0.018054276704788208,
      "learning_rate": 3.374870197300104e-06,
      "loss": 0.0008,
      "step": 2010
    },
    {
      "epoch": 9.439252336448599,
      "grad_norm": 0.014591304585337639,
      "learning_rate": 3.1152647975077884e-06,
      "loss": 0.0009,
      "step": 2020
    },
    {
      "epoch": 9.485981308411215,
      "grad_norm": 0.012788581661880016,
      "learning_rate": 2.8556593977154727e-06,
      "loss": 0.0008,
      "step": 2030
    },
    {
      "epoch": 9.532710280373832,
      "grad_norm": 0.014811884611845016,
      "learning_rate": 2.596053997923157e-06,
      "loss": 0.0771,
      "step": 2040
    },
    {
      "epoch": 9.57943925233645,
      "grad_norm": 0.016489511355757713,
      "learning_rate": 2.3364485981308413e-06,
      "loss": 0.0009,
      "step": 2050
    },
    {
      "epoch": 9.626168224299064,
      "grad_norm": 0.016796458512544632,
      "learning_rate": 2.0768431983385256e-06,
      "loss": 0.0008,
      "step": 2060
    },
    {
      "epoch": 9.672897196261681,
      "grad_norm": 0.019521789625287056,
      "learning_rate": 1.8172377985462099e-06,
      "loss": 0.001,
      "step": 2070
    },
    {
      "epoch": 9.719626168224298,
      "grad_norm": 0.02444816380739212,
      "learning_rate": 1.5576323987538942e-06,
      "loss": 0.0009,
      "step": 2080
    },
    {
      "epoch": 9.766355140186915,
      "grad_norm": 0.1024751141667366,
      "learning_rate": 1.2980269989615785e-06,
      "loss": 0.0008,
      "step": 2090
    },
    {
      "epoch": 9.813084112149532,
      "grad_norm": 0.014678437262773514,
      "learning_rate": 1.0384215991692628e-06,
      "loss": 0.0009,
      "step": 2100
    },
    {
      "epoch": 9.85981308411215,
      "grad_norm": 0.021236028522253036,
      "learning_rate": 7.788161993769471e-07,
      "loss": 0.0009,
      "step": 2110
    },
    {
      "epoch": 9.906542056074766,
      "grad_norm": 0.01776193641126156,
      "learning_rate": 5.192107995846314e-07,
      "loss": 0.0008,
      "step": 2120
    },
    {
      "epoch": 9.953271028037383,
      "grad_norm": 0.014039851725101471,
      "learning_rate": 2.596053997923157e-07,
      "loss": 0.095,
      "step": 2130
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.021293066442012787,
      "learning_rate": 0.0,
      "loss": 0.0008,
      "step": 2140
    },
    {
      "epoch": 10.0,
      "eval_accuracy": 0.955607476635514,
      "eval_f1": 0.9430464411029325,
      "eval_loss": 0.2893966734409332,
      "eval_precision": 0.9495410236735158,
      "eval_recall": 0.9370579133510168,
      "eval_runtime": 112.8356,
      "eval_samples_per_second": 3.793,
      "eval_steps_per_second": 0.479,
      "step": 2140
    }
  ],
  "logging_steps": 10,
  "max_steps": 2140,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.8811154536e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
